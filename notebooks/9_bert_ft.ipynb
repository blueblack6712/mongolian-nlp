{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dbe0030-a548-4287-9e78-01d0e15a093c",
   "metadata": {},
   "source": [
    "Fine-tune using BERT-based-multiligual_cased from hugging face\n",
    "\n",
    "-we download all files needed because this is run in Autodl and there's no VPN to access Hugging face's API from https://huggingface.co/tugstugi/bert-base-mongolian-cased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce6f7ac-588d-4582-a083-d277487eac5f",
   "metadata": {},
   "source": [
    "#1 Download and upgrade required Libraries(make sure that they are compatible with your environment) before running all lines of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "339167d8-d086-41c1-9b62-963beb71e0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (4.50.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (2.6.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (4.67.1)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.9.1)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (0.21.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (3.18.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (0.5.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (0.29.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (24.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (2024.11.6)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (11.2.1.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (3.2.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (12.4.127)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (4.12.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (2.21.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 5)) (1.4.2)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 5)) (8.1.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 2)) (3.0.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (2025.1.31)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dff0dfd1-01bb-4cd8-a38c-ea891b23e122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.45.4)\n",
      "\u001b[33mDEPRECATION: The HTML index page being used (http://mirrors.aliyun.com/pypi/simple/bitsandbytes/) is not a proper HTML 5 document. This is in violation of PEP 503 which requires these pages to be well-formed HTML 5 documents. Please reach out to the owners of this index page, and ask them to update this index page to a valid HTML 5 document. pip 22.2 will enforce this behaviour change. Discussion can be found at https://github.com/pypa/pip/issues/10825\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f31ee8c3-8d05-4524-932c-c9e2af9512ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (6.30.2)\n",
      "\u001b[33mDEPRECATION: The HTML index page being used (http://mirrors.aliyun.com/pypi/simple/protobuf/) is not a proper HTML 5 document. This is in violation of PEP 503 which requires these pages to be well-formed HTML 5 documents. Please reach out to the owners of this index page, and ask them to update this index page to a valid HTML 5 document. pip 22.2 will enforce this behaviour change. Discussion can be found at https://github.com/pypa/pip/issues/10825\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
      "\u001b[33mDEPRECATION: The HTML index page being used (http://mirrors.aliyun.com/pypi/simple/sentencepiece/) is not a proper HTML 5 document. This is in violation of PEP 503 which requires these pages to be well-formed HTML 5 documents. Please reach out to the owners of this index page, and ask them to update this index page to a valid HTML 5 document. pip 22.2 will enforce this behaviour change. Discussion can be found at https://github.com/pypa/pip/issues/10825\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.50.1)\n",
      "\u001b[33mDEPRECATION: The HTML index page being used (http://mirrors.aliyun.com/pypi/simple/transformers/) is not a proper HTML 5 document. This is in violation of PEP 503 which requires these pages to be well-formed HTML 5 documents. Please reach out to the owners of this index page, and ask them to update this index page to a valid HTML 5 document. pip 22.2 will enforce this behaviour change. Discussion can be found at https://github.com/pypa/pip/issues/10825\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade protobuf sentencepiece transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6396063-5652-479b-ae6e-1bc140eacd2c",
   "metadata": {},
   "source": [
    "#2 (skip this if you use API from hugging face) Try and load downloaded files for BERT-base-multiligual-cased and test run to see if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e987c43c-3c8a-4b6d-a6c4-ff47f514e6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['С', '##үү', '##лийн', 'тав', '##ан', 'жил', 'дараа', '##лан']\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# 加载 tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    \"/dev/shm/bert-base-multiligual-cased\",  # 绝对路径，无尾随斜杠\n",
    "    local_files_only=True\n",
    ")\n",
    "\n",
    "# 加载模型\n",
    "model = BertModel.from_pretrained(\n",
    "    \"/dev/shm/bert-base-multiligual-cased\",\n",
    "    local_files_only=True\n",
    ")\n",
    "\n",
    "# 测试分词\n",
    "text = \"Сүүлийн таван жил дараалан\"\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(tokens)  # 应该输出类似 ['▁Сүү', '##лийн', '▁таван', '▁жил', '▁дараалан']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f34679d-9130-4c42-a912-c039882ec7dd",
   "metadata": {},
   "source": [
    "#3 Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e05628e1-e9de-4b82-b536-24f9330648c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizerFast, BertForTokenClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "BERT_MODEL_PATH = \"/dev/shm/bert-base-multiligual-cased\"\n",
    "TRAIN_DATASET_PATH = \"/dev/shm/train.jsonl\"\n",
    "VALID_DATASET_PATH = \"/dev/shm/validation.jsonl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4646ca9b-7e10-415c-91a6-52ca66150f24",
   "metadata": {},
   "source": [
    "#4 Memory Management Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "807c4cbc-90e0-4139-9a18-741695d0bd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_cuda_memory():\n",
    "    \"\"\"Clears unused GPU memory to prevent OutOfMemory errors.\"\"\"\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2502993-62c5-41ed-813d-a36bbdfbc055",
   "metadata": {},
   "source": [
    "#5 Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b61896f-4e66-4f1f-a468-3294414899bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(BERT_MODEL_PATH, local_files_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f62ada-c0dd-452f-8bf2-6bc92d577ccb",
   "metadata": {},
   "source": [
    "#6 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5921ce6-478d-4936-900d-04cc2f5afddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {\"train\": TRAIN_DATASET_PATH, \"validation\": VALID_DATASET_PATH}\n",
    "dataset = load_dataset(\"json\", data_files=data_files)\n",
    "\n",
    "train_dataset = dataset[\"train\"]\n",
    "val_dataset = dataset[\"validation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ae0e9c-e295-4e51-92f8-9a9c85ae2c74",
   "metadata": {},
   "source": [
    "#7 Determine Number of Labels (Mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b55a705-859e-4cc7-827b-b26c95039d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_labels(dataset):\n",
    "    labels = set()\n",
    "    for example in dataset:\n",
    "        labels.update(example[\"pos_tags\"])\n",
    "    return sorted(labels)\n",
    "\n",
    "unique_labels = get_unique_labels(train_dataset)\n",
    "label2id = {label: i for i, label in enumerate(unique_labels)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "num_labels = len(unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbe5ce0-2981-4677-9480-7995dc3d37ba",
   "metadata": {},
   "source": [
    "#8 Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0e76d3-143c-48bf-9afa-1b2b9c66d247",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForTokenClassification.from_pretrained(\n",
    "    BERT_MODEL_PATH, \n",
    "    num_labels=num_labels, \n",
    "    local_files_only=True,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a3b0ee-0bcf-4af5-b59c-f81fadd1be27",
   "metadata": {},
   "source": [
    "#9 Tokenization & Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626d3457-8078-4ac0-832b-a121e66eeeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(example):\n",
    "    tokens = example[\"tokens\"]\n",
    "    pos_tags = example[\"pos_tags\"]\n",
    "    \n",
    "    encoding = tokenizer(tokens,\n",
    "                         is_split_into_words=True,\n",
    "                         truncation=True,\n",
    "                         padding=\"max_length\",\n",
    "                         max_length=128,\n",
    "                         return_tensors=\"pt\")\n",
    "\n",
    "    word_ids = encoding.word_ids(batch_index=0)\n",
    "    labels = [-100 if word_id is None else label2id.get(pos_tags[word_id], 0) for word_id in word_ids]\n",
    "\n",
    "    encoding[\"labels\"] = labels\n",
    "    return {key: torch.tensor(val).squeeze(0) for key, val in encoding.items()}\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_and_align_labels, remove_columns=[\"tokens\", \"pos_tags\"])\n",
    "val_dataset = val_dataset.map(tokenize_and_align_labels, remove_columns=[\"tokens\", \"pos_tags\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaccbc2b-8314-4810-b0c8-f384e65490f2",
   "metadata": {},
   "source": [
    "#10 Define Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7843db-9ed5-4d61-bddb-aa31b5c757ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_labels = []\n",
    "    true_preds = []\n",
    "    for pred_seq, label_seq in zip(predictions, labels):\n",
    "        for p_item, l_item in zip(pred_seq, label_seq):\n",
    "            if l_item != -100:\n",
    "                true_labels.append(id2label[l_item])\n",
    "                true_preds.append(id2label[p_item])\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, true_preds, average=\"weighted\")\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42f651d-5196-46f1-95f2-bad4312ac5a1",
   "metadata": {},
   "source": [
    "#11 Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d591d2c9-eb9f-4bb5-bce5-d244df1c2610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_args(batch_size=8, grad_accum=8):\n",
    "    return TrainingArguments(\n",
    "        output_dir=\"/dev/shm/bert_finetuned\",\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=500,\n",
    "        logging_steps=100,\n",
    "        save_total_limit=1,\n",
    "        logging_dir=\"/dev/shm/logs\",\n",
    "        fp16=True,\n",
    "        gradient_accumulation_steps=grad_accum,\n",
    "        bf16=False,\n",
    "        optim=\"adamw_torch_fused\",\n",
    "        gradient_checkpointing=True,\n",
    "        dataloader_num_workers=4,\n",
    "        torch_compile=True,\n",
    "        report_to=\"none\",\n",
    "        save_steps=500\n",
    "    )\n",
    "\n",
    "training_args = get_training_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f179d87-affb-4149-820f-230f4c0ac7b6",
   "metadata": {},
   "source": [
    "#12 Initialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa33a5bb-4db0-4d9b-88b7-1a82c0d0f1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3361a917-9703-4da2-9f8d-254873daec95",
   "metadata": {},
   "source": [
    "#13 Run Training with Memory Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f1b406-b00b-4970-99bf-153e707ea6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fine-tuning started at:\", time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "try:\n",
    "    trainer.train()\n",
    "except RuntimeError as e:\n",
    "    if \"out of memory\" in str(e).lower():\n",
    "        print(\"CUDA Out of Memory! Reducing batch size...\")\n",
    "        clear_cuda_memory()\n",
    "\n",
    "        # Retry with lower batch size\n",
    "        new_batch_size = max(1, training_args.per_device_train_batch_size // 2)\n",
    "        new_grad_accum = training_args.gradient_accumulation_steps * 2\n",
    "\n",
    "        training_args = get_training_args(batch_size=new_batch_size, grad_accum=new_grad_accum)\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=val_dataset,\n",
    "            compute_metrics=compute_metrics,\n",
    "            tokenizer=tokenizer\n",
    "        )\n",
    "        trainer.train()\n",
    "\n",
    "print(\"Fine-tuning finished at:\", time.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f699898a-57f5-4e24-959a-73f869ec2971",
   "metadata": {},
   "source": [
    "#14 Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f49293d-d554-4e4d-9817-22ffa34535fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"/dev/shm/bert_finetuned\")\n",
    "print(\"Final model saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
